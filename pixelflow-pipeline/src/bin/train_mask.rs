//! Train the unified mask head for rule filtering.
//!
//! Uses mask_training.jsonl generated by gen_mask_data.
//!
//! # Usage
//!
//! ```bash
//! cargo run -p pixelflow-pipeline --bin train_mask --release --features training
//! ```

use std::fs::File;
use std::io::{BufRead, BufReader};
use std::path::PathBuf;

use clap::Parser;
use serde::Deserialize;

use pixelflow_ir::Expr;
use pixelflow_pipeline::training::factored::parse_kernel_code;
use pixelflow_search::nnue::{ExprNnue, RULE_FEATURE_DIM};

/// Train the unified mask head.
#[derive(Parser, Debug)]
#[command(name = "train_mask")]
#[command(about = "Train unified mask head for rule filtering")]
struct Args {
    /// Path to mask training data
    #[arg(long, default_value = "pixelflow-pipeline/data/mask_training.jsonl")]
    data: String,

    /// Path to load pre-trained model (optional, starts from scratch if not provided)
    #[arg(long)]
    load_model: Option<String>,

    /// Path to judge model for embedding bootstrapping.
    /// When provided, copies trained backbone (embeddings, w1, b1) from judge.
    /// Use this to share embeddings between judge and mask heads.
    #[arg(long, default_value = "pixelflow-pipeline/data/judge.bin")]
    load_judge: String,

    /// Skip loading judge embeddings (use random init instead)
    #[arg(long, default_value_t = false)]
    no_judge: bool,

    /// Path to save trained model
    #[arg(short, long, default_value = "pixelflow-pipeline/data/mask_model.bin")]
    output: String,

    /// Learning rate
    #[arg(long, default_value_t = 0.001)]
    lr: f32,

    /// Number of training epochs
    #[arg(long, default_value_t = 10)]
    epochs: usize,

    /// False positive weight (penalty for predicting match when it didn't)
    #[arg(long, default_value_t = 1.0)]
    fp_weight: f32,

    /// False negative weight (penalty for missing a match - should be high!)
    #[arg(long, default_value_t = 10.0)]
    fn_weight: f32,

    /// Validation split ratio
    #[arg(long, default_value_t = 0.1)]
    val_split: f32,

    /// Random seed
    #[arg(long, default_value_t = 42)]
    seed: u64,

    /// Maximum samples to load (0 = all)
    #[arg(long, default_value_t = 0)]
    max_samples: usize,
}

/// Training sample from mask_training.jsonl
#[derive(Debug, Deserialize)]
struct MaskSample {
    expression: String,
    rule_idx: usize,
    #[allow(dead_code)]
    rule_name: String,
    rule_features: [f32; RULE_FEATURE_DIM],
    fired: bool,
}

/// Parsed sample ready for training
struct ParsedSample {
    expr: Expr,
    rule_features: [f32; RULE_FEATURE_DIM],
    rule_idx: usize,
    fired: bool,
}

fn main() {
    let args = Args::parse();
    let workspace_root = find_workspace_root();

    // Load or create model
    let mut model = if let Some(model_path) = &args.load_model {
        let path = workspace_root.join(model_path);
        println!("Loading pre-trained model from: {}", path.display());
        ExprNnue::load(&path).expect("Failed to load model")
    } else if !args.no_judge {
        // Load judge model to bootstrap embeddings
        let judge_path = workspace_root.join(&args.load_judge);
        println!("Loading judge for embedding bootstrapping: {}", judge_path.display());

        match ExprNnue::load(&judge_path) {
            Ok(judge) => {
                println!("  ✓ Loaded judge backbone (embeddings, w1, b1)");
                let mut model = judge.with_randomized_mask_weights(args.seed);
                println!("  ✓ Randomized mask-specific weights");
                model
            }
            Err(e) => {
                eprintln!("  ✗ Failed to load judge: {}", e);
                eprintln!("  → Falling back to random initialization");
                eprintln!("  → (use --no-judge to skip this warning)");
                let mut model = ExprNnue::new_with_latency_prior(args.seed);
                model.randomize_mask_only(args.seed);
                model
            }
        }
    } else {
        println!("Creating new model with random initialization (--no-judge)");
        let mut model = ExprNnue::new_with_latency_prior(args.seed);
        model.randomize_mask_only(args.seed);
        model
    };

    // Load training data
    let data_path = workspace_root.join(&args.data);
    println!("Loading training data from: {}", data_path.display());

    let file = File::open(&data_path).expect("Failed to open mask_training.jsonl");
    let reader = BufReader::new(file);

    let mut samples: Vec<ParsedSample> = Vec::new();
    let mut parse_failures = 0usize;

    for (idx, line) in reader.lines().enumerate() {
        let line = line.expect("Failed to read line");
        if line.trim().is_empty() {
            continue;
        }

        let sample: MaskSample = serde_json::from_str(&line).expect("Failed to parse sample");

        // Parse expression
        match parse_kernel_code(&sample.expression) {
            Some(expr) => {
                samples.push(ParsedSample {
                    expr,
                    rule_features: sample.rule_features,
                    rule_idx: sample.rule_idx,
                    fired: sample.fired,
                });
            }
            None => {
                parse_failures += 1;
            }
        }

        if args.max_samples > 0 && samples.len() >= args.max_samples {
            break;
        }

        if idx % 10000 == 0 && idx > 0 {
            println!("  Loaded {} samples...", samples.len());
        }
    }

    println!(
        "Loaded {} samples ({} parse failures)",
        samples.len(),
        parse_failures
    );

    // Count class distribution
    let num_positive = samples.iter().filter(|s| s.fired).count();
    let num_negative = samples.len() - num_positive;
    println!(
        "Class distribution: {} positive ({:.1}%), {} negative ({:.1}%)",
        num_positive,
        num_positive as f32 / samples.len() as f32 * 100.0,
        num_negative,
        num_negative as f32 / samples.len() as f32 * 100.0
    );

    // Shuffle and split
    let mut rng_state = args.seed;
    let mut next_rand = || {
        rng_state = rng_state.wrapping_mul(6364136223846793005).wrapping_add(1);
        (rng_state >> 33) as f32 / (1u64 << 31) as f32
    };

    // Fisher-Yates shuffle
    for i in (1..samples.len()).rev() {
        let j = (next_rand() * (i + 1) as f32) as usize;
        samples.swap(i, j);
    }

    let val_size = (samples.len() as f32 * args.val_split) as usize;
    let (val_samples, train_samples) = samples.split_at(val_size);

    println!(
        "Split: {} training, {} validation",
        train_samples.len(),
        val_samples.len()
    );

    // Training loop
    println!("\n=== Training ===");
    println!(
        "lr={}, fp_weight={}, fn_weight={}",
        args.lr, args.fp_weight, args.fn_weight
    );

    for epoch in 0..args.epochs {
        let mut epoch_loss = 0.0f32;
        let mut correct = 0usize;
        let mut false_positives = 0usize;
        let mut false_negatives = 0usize;

        // Train on all samples
        for sample in train_samples {
            let loss = model.train_mask_step(
                &sample.expr,
                &sample.rule_features,
                sample.rule_idx,
                sample.fired,
                args.lr,
                args.fp_weight,
                args.fn_weight,
            );
            epoch_loss += loss;

            // Compute prediction for metrics
            let score = model.mask_score_single(
                &sample.expr,
                &sample.rule_features,
                sample.rule_idx,
            );
            let predicted = score > 0.0; // sigmoid(0) = 0.5 threshold

            if predicted == sample.fired {
                correct += 1;
            } else if predicted && !sample.fired {
                false_positives += 1;
            } else {
                false_negatives += 1;
            }
        }

        let train_acc = correct as f32 / train_samples.len() as f32;
        let train_loss = epoch_loss / train_samples.len() as f32;

        // Validation
        let (val_acc, val_recall, val_precision) = evaluate(&model, val_samples);

        println!(
            "Epoch {}/{}: train_loss={:.4}, train_acc={:.1}%, val_acc={:.1}%, val_recall={:.1}%, val_precision={:.1}%, FP={}, FN={}",
            epoch + 1,
            args.epochs,
            train_loss,
            train_acc * 100.0,
            val_acc * 100.0,
            val_recall * 100.0,
            val_precision * 100.0,
            false_positives,
            false_negatives,
        );
    }

    // Final evaluation
    println!("\n=== Final Evaluation ===");
    let (final_acc, final_recall, final_precision) = evaluate(&model, val_samples);
    println!(
        "Validation: acc={:.1}%, recall={:.1}%, precision={:.1}%",
        final_acc * 100.0,
        final_recall * 100.0,
        final_precision * 100.0
    );

    // Save model
    let output_path = workspace_root.join(&args.output);
    model.save(&output_path).expect("Failed to save model");
    println!("\nSaved model to: {}", output_path.display());
}

/// Evaluate model on a set of samples.
/// Returns (accuracy, recall, precision).
fn evaluate(model: &ExprNnue, samples: &[ParsedSample]) -> (f32, f32, f32) {
    let mut correct = 0usize;
    let mut true_positives = 0usize;
    let mut false_positives = 0usize;
    let mut false_negatives = 0usize;

    for sample in samples {
        let score = model.mask_score_single(
            &sample.expr,
            &sample.rule_features,
            sample.rule_idx,
        );
        let predicted = score > 0.0; // sigmoid(0) = 0.5 threshold

        if predicted == sample.fired {
            correct += 1;
            if predicted {
                true_positives += 1;
            }
        } else if predicted && !sample.fired {
            false_positives += 1;
        } else {
            false_negatives += 1;
        }
    }

    let accuracy = correct as f32 / samples.len() as f32;
    let recall = if true_positives + false_negatives > 0 {
        true_positives as f32 / (true_positives + false_negatives) as f32
    } else {
        1.0
    };
    let precision = if true_positives + false_positives > 0 {
        true_positives as f32 / (true_positives + false_positives) as f32
    } else {
        1.0
    };

    (accuracy, recall, precision)
}

/// Find workspace root.
fn find_workspace_root() -> PathBuf {
    let mut current = std::env::current_dir().expect("Failed to get current directory");
    loop {
        let cargo_toml = current.join("Cargo.toml");
        if cargo_toml.exists() {
            let contents = std::fs::read_to_string(&cargo_toml).unwrap_or_default();
            if contents.contains("[workspace]") {
                return current;
            }
        }
        if !current.pop() {
            return std::env::current_dir().expect("Failed to get current directory");
        }
    }
}
