//! # Code Generation
//!
//! Emits Rust code from the analyzed AST.
//!
//! ## Architecture: ZST Expression + Let/Var Binding
//!
//! PixelFlow expressions are Copy when all components are ZST (zero-sized types).
//! The coordinate variables X, Y, Z, W are ZST, and so are Var<N> references.
//! This means expressions using Var<N> remain Copy.
//!
//! The solution is a two-layer architecture:
//!
//! 1. **ZST Expression**: Built using coordinate variables (X, Y, Z, W) and Var<N>
//! 2. **Value Struct**: Stores non-ZST captured parameters (f32 values)
//! 3. **Let/Var binding**: Nested Let wrappers extend domain with parameter values
//!
//! ## Let/Var Binding (Peano-Encoded Stack)
//!
//! Parameters are bound using nested `Let::new()` calls that extend the domain:
//! - First param → deepest binding → `Var::<N{n-1}>`
//! - Last param → shallowest binding → `Var::<N0>` (head of stack)
//!
//! This allows **unlimited parameters** (no longer limited to 2).
//!
//! ## Example Transformation
//!
//! ```text
//! // User writes:
//! kernel!(|cx: f32, cy: f32, cz: f32| X - cx + Y - cy + Z - cz)
//!
//! // Becomes:
//! struct __Kernel { cx: f32, cy: f32, cz: f32 }
//!
//! impl Manifold<Field4> for __Kernel {
//!     fn eval(&self, __p: Field4) -> Field {
//!         // ZST expression using Var<N> (Copy!)
//!         let __expr = X - Var::<N2>::new() + Y - Var::<N1>::new() + Z - Var::<N0>::new();
//!         // Nested Let bindings extend domain with parameter values
//!         Let::new(self.cx,
//!           Let::new(self.cy,
//!             Let::new(self.cz,
//!               __expr))).eval(__p)
//!     }
//! }
//! ```

use crate::annotate::{
    annotate, AnnotatedCall, AnnotatedExpr, AnnotatedStmt, AnnotationCtx, CollectedLiteral,
};
use crate::ast::{BinaryOp, ParamKind, UnaryOp};
use crate::sema::AnalyzedKernel;
use crate::symbol::SymbolKind;
use proc_macro2::TokenStream;
use quote::{ToTokens, format_ident, quote};
use std::collections::HashMap;

// Peano type names (N0, N1, ..., N255) are now generated dynamically.
// This removes the hardcoded limit. Types are generated by generate_peano_types!
// macro in pixelflow-core and referenced here using format!("N{}", idx).

/// Emit Rust code for an analyzed kernel.
pub fn emit(analyzed: AnalyzedKernel) -> TokenStream {
    let mut emitter = CodeEmitter::new(&analyzed);
    emitter.emit_kernel()
}

/// The code emitter state.
struct CodeEmitter<'a> {
    analyzed: &'a AnalyzedKernel,
    /// Maps parameter names to their Peano index for Var<N> access.
    /// First param → highest index (deepest in stack), last param → N0 (head).
    param_indices: HashMap<String, usize>,
    /// Maps manifold parameter names to their generic type index (M0, M1, ...).
    manifold_indices: HashMap<String, usize>,
    /// Whether we're generating for a Jet domain (Jet2, Jet3).
    /// If true, f32 literals must be wrapped as constant jets.
    use_jet_wrapper: bool,
    /// Collected literals from annotation pass (for Let bindings in Jet mode).
    collected_literals: Vec<CollectedLiteral>,
}

impl<'a> CodeEmitter<'a> {
    fn new(analyzed: &'a AnalyzedKernel) -> Self {
        // Compute Peano indices for ALL parameters (both scalar and manifold).
        // With n parameters, first param is at index n-1, last param is at index 0.
        let n = analyzed.def.params.len();
        let mut param_indices = HashMap::new();
        for (i, param) in analyzed.def.params.iter().enumerate() {
            // First param (i=0) gets highest index (n-1), last param gets 0
            let peano_idx = n - 1 - i;
            param_indices.insert(param.name.to_string(), peano_idx);
        }

        // Compute generic type indices for manifold parameters (M0, M1, ...).
        // These are numbered in declaration order.
        let mut manifold_indices = HashMap::new();
        let mut manifold_count = 0;
        for param in &analyzed.def.params {
            if matches!(param.kind, ParamKind::Manifold) {
                manifold_indices.insert(param.name.to_string(), manifold_count);
                manifold_count += 1;
            }
        }

        // Determine if we need to wrap literals for Jet domains
        let use_jet_wrapper = match &analyzed.def.return_ty {
            Some(ty) => {
                let ty_str = quote! { #ty }.to_string();
                ty_str.contains("Jet3") || ty_str.contains("Jet2")
            }
            None => false,
        };

        CodeEmitter {
            analyzed,
            param_indices,
            manifold_indices,
            use_jet_wrapper,
            collected_literals: Vec::new(), // Populated during emit_kernel
        }
    }

    /// Emit the complete kernel definition.
    fn emit_kernel(&mut self) -> TokenStream {
        let params = &self.analyzed.def.params;

        // Count manifold parameters for generic type generation
        let manifold_count = self.manifold_indices.len();

        // Generate generic type parameter names (M0, M1, ...)
        let generic_names: Vec<syn::Ident> = (0..manifold_count)
            .map(|i| format_ident!("M{}", i))
            .collect();

        // Generate struct fields:
        // - Manifold params → generic field `inner: M0`
        // - Scalar params → concrete field `r: f32`
        let struct_fields: Vec<TokenStream> = params
            .iter()
            .map(|p| {
                let name = &p.name;
                match &p.kind {
                    ParamKind::Scalar(ty) => quote! { #name: #ty },
                    ParamKind::Manifold => {
                        let idx = self.manifold_indices[&name.to_string()];
                        let generic_name = &generic_names[idx];
                        quote! { #name: #generic_name }
                    }
                }
            })
            .collect();

        // Generate struct field names for construction
        let field_names: Vec<_> = params.iter().map(|p| &p.name).collect();

        // Generate closure parameters:
        // - Manifold params → just the name (type inferred from generic)
        // - Scalar params → `name: type`
        let closure_params: Vec<TokenStream> = params
            .iter()
            .map(|p| {
                let name = &p.name;
                match &p.kind {
                    ParamKind::Scalar(ty) => quote! { #name: #ty },
                    ParamKind::Manifold => quote! { #name },
                }
            })
            .collect();

        // Run annotation pass to collect literals and assign Var indices
        // NOTE: We collect literals even in non-Jet mode, but only bind them in Jet mode
        let annotation_ctx = AnnotationCtx::new();
        let (annotated_body, _, collected_literals) = annotate(&self.analyzed.def.body, annotation_ctx);
        self.collected_literals = collected_literals;

        // Only adjust param indices for literals if we're in Jet mode
        // In non-Jet mode, literals are inlined directly (no Let bindings)
        if self.use_jet_wrapper {
            let literal_count = self.collected_literals.len();
            // Adjust param indices to account for literals (literals are innermost)
            // Original: param0→n-1, param1→n-2, ..., param_{n-1}→0
            // Adjusted: param0→n+m-1, param1→n+m-2, ..., param_{n-1}→m
            for (_, idx) in self.param_indices.iter_mut() {
                *idx += literal_count;
            }
        }

        // Transform and emit the body as a ZST expression
        let body = self.emit_annotated_expr(&annotated_body);

        // Generate the Peano type imports needed based on parameter + literal count
        let peano_imports = self.emit_peano_imports();

        // Determine output type and infer domain type from it
        // - Jet3 output → Jet3_4 domain (for autodiff)
        // - Field output (or default) → Field4 domain
        let (output_type, domain_type, scalar_type) = match &self.analyzed.def.return_ty {
            Some(ty) => {
                // Check if return type is Jet3 (or Jet2, Jet4, etc.)
                let ty_str = quote! { #ty }.to_string();
                if ty_str.contains("Jet3") {
                    (
                        quote! { #ty },
                        quote! { (::pixelflow_core::jet::Jet3, ::pixelflow_core::jet::Jet3, ::pixelflow_core::jet::Jet3, ::pixelflow_core::jet::Jet3) },
                        quote! { ::pixelflow_core::jet::Jet3 },
                    )
                } else if ty_str.contains("Jet2") {
                    (
                        quote! { #ty },
                        quote! { (::pixelflow_core::jet::Jet2, ::pixelflow_core::jet::Jet2, ::pixelflow_core::jet::Jet2, ::pixelflow_core::jet::Jet2) },
                        quote! { ::pixelflow_core::jet::Jet2 },
                    )
                } else {
                    (
                        quote! { #ty },
                        quote! { (::pixelflow_core::Field, ::pixelflow_core::Field, ::pixelflow_core::Field, ::pixelflow_core::Field) },
                        quote! { ::pixelflow_core::Field },
                    )
                }
            }
            None => (
                quote! { ::pixelflow_core::Field },
                quote! { (::pixelflow_core::Field, ::pixelflow_core::Field, ::pixelflow_core::Field, ::pixelflow_core::Field) },
                quote! { ::pixelflow_core::Field },
            ),
        };

        // Generate the Let/Var binding to inject parameters (use stored use_jet_wrapper)
        let (manifold_eval_stmts, at_binding) = self.emit_unified_binding();

        // Handle empty vs non-empty params, with or without generics
        if params.is_empty() {
            // No parameters - unit struct is always Copy
            quote! {
                {
                    type __Domain = #domain_type;
                    type __Scalar = #scalar_type;

                    #[derive(Clone, Copy)]
                    struct __Kernel;

                    impl ::pixelflow_core::Manifold<__Domain> for __Kernel {
                        type Output = #output_type;

                        #[inline(always)]
                        fn eval(
                            &self,
                            __p: __Domain,
                        ) -> #output_type {
                            use ::pixelflow_core::{X, Y, Z, W, ManifoldExt, ManifoldCompat, Manifold, Let, Var, WithContext, CtxVar, GradientMag2D, GradientMag3D, Antialias2D, Antialias3D, Curvature2D, Normalized2D, Normalized3D, V, DX, DY, DZ, DXX, DXY, DYY};
                            #peano_imports

                            let __expr = { #body };
                            #at_binding
                        }
                    }

                    || __Kernel
                }
            }
        } else if manifold_count == 0 && params.len() == 1 {
            // Single scalar parameter - derive Copy (f32, i32, etc. are Copy)
            quote! {
                {
                    type __Domain = #domain_type;
                    type __Scalar = #scalar_type;

                    #[derive(Clone, Copy)]
                    struct __Kernel { #(#struct_fields),* }

                    impl ::pixelflow_core::Manifold<__Domain> for __Kernel {
                        type Output = #output_type;

                        #[inline(always)]
                        fn eval(
                            &self,
                            __p: __Domain,
                        ) -> #output_type {
                            use ::pixelflow_core::{X, Y, Z, W, ManifoldExt, ManifoldCompat, Manifold, Let, Var, WithContext, CtxVar, GradientMag2D, GradientMag3D, Antialias2D, Antialias3D, Curvature2D, Normalized2D, Normalized3D, V, DX, DY, DZ, DXX, DXY, DYY};
                            #peano_imports

                            let __expr = { #body };
                            #at_binding
                        }
                    }

                    |#(#closure_params),*| __Kernel { #(#field_names),* }
                }
            }
        } else if manifold_count == 0 {
            // Multiple scalar parameters - Clone but not Copy
            quote! {
                {
                    type __Domain = #domain_type;
                    type __Scalar = #scalar_type;

                    #[derive(Clone)]
                    struct __Kernel { #(#struct_fields),* }

                    impl ::pixelflow_core::Manifold<__Domain> for __Kernel {
                        type Output = #output_type;

                        #[inline(always)]
                        fn eval(
                            &self,
                            __p: __Domain,
                        ) -> #output_type {
                            use ::pixelflow_core::{X, Y, Z, W, ManifoldExt, ManifoldCompat, Manifold, Let, Var, WithContext, CtxVar, GradientMag2D, GradientMag3D, Antialias2D, Antialias3D, Curvature2D, Normalized2D, Normalized3D, V, DX, DY, DZ, DXX, DXY, DYY};
                            #peano_imports

                            let __expr = { #body };
                            #at_binding
                        }
                    }

                    |#(#closure_params),*| __Kernel { #(#field_names),* }
                }
            }
        } else if manifold_count == 1 && params.len() == 1 {
            // Single manifold parameter - conditional Copy when M0: Copy
            // This enables ZST composition: if inner kernel is ZST+Copy, outer is too

            // Check if we have an explicit return type - if not, use generic domain
            let has_return_type = self.analyzed.def.return_ty.is_some();

            if has_return_type {
                // Explicit return type → fixed domain (Jet2_4, Jet3_4, or Field4)
                let trait_bounds: Vec<TokenStream> = generic_names
                    .iter()
                    .map(|g| {
                        quote! { #g: ::pixelflow_core::Manifold<__Domain, Output = __Scalar> }
                    })
                    .collect();

                quote! {
                    {
                        type __Domain = #domain_type;
                        type __Scalar = #scalar_type;

                        struct __Kernel<#(#generic_names),*> { #(#struct_fields),* }

                        // Clone when inner is Clone
                        impl<#(#generic_names: Clone),*> Clone for __Kernel<#(#generic_names),*> {
                            fn clone(&self) -> Self {
                                Self { #(#field_names: self.#field_names.clone()),* }
                            }
                        }

                        // Copy when inner is Copy (ZST kernels are Copy via zst.rs)
                        impl<#(#generic_names: Copy),*> Copy for __Kernel<#(#generic_names),*> {}

                        impl<#(#generic_names),*> ::pixelflow_core::Manifold<__Domain> for __Kernel<#(#generic_names),*>
                        where
                            #(#trait_bounds),*
                        {
                            type Output = #output_type;

                            #[inline(always)]
                            fn eval(
                                &self,
                                __p: __Domain,
                            ) -> #output_type {
                                use ::pixelflow_core::{X, Y, Z, W, ManifoldExt, ManifoldCompat, Manifold, Let, Var, WithContext, CtxVar, GradientMag2D, GradientMag3D, Antialias2D, Antialias3D, Curvature2D, Normalized2D, Normalized3D, V, DX, DY, DZ, DXX, DXY, DYY};
                                #peano_imports

                                // Evaluate manifold parameters at current point (borrows via &self)
                                #manifold_eval_stmts

                                // Build the ZST expression tree using Var<N> for ALL parameters
                                let __expr = { #body };

                                // Wrap in nested Let bindings and evaluate
                                #at_binding
                            }
                        }

                        |#(#closure_params),*| __Kernel { #(#field_names),* }
                    }
                }
            } else {
                // No return type → generic domain P
                // This allows the kernel to adapt to whatever domain the manifold param requires
                // Output is Field since derivative accessors (V, DX, DY) return Field

                quote! {
                    {
                        struct __Kernel<#(#generic_names),*> { #(#struct_fields),* }

                        // Clone when inner is Clone
                        impl<#(#generic_names: Clone),*> Clone for __Kernel<#(#generic_names),*> {
                            fn clone(&self) -> Self {
                                Self { #(#field_names: self.#field_names.clone()),* }
                            }
                        }

                        // Copy when inner is Copy (ZST kernels are Copy via zst.rs)
                        impl<#(#generic_names: Copy),*> Copy for __Kernel<#(#generic_names),*> {}

                        // Generic over domain P - works with whatever domain the manifold param requires
                        impl<#(#generic_names),*, __P> ::pixelflow_core::Manifold<__P> for __Kernel<#(#generic_names),*>
                        where
                            __P: Copy + Send + Sync + ::pixelflow_core::Spatial,
                            #(#generic_names: ::pixelflow_core::Manifold<__P>),*,
                            // Output must be Copy+Send+Sync for Let binding
                            #(<#generic_names as ::pixelflow_core::Manifold<__P>>::Output: Copy + Send + Sync),*,
                        {
                            type Output = ::pixelflow_core::Field;

                            #[inline(always)]
                            fn eval(
                                &self,
                                __p: __P,
                            ) -> ::pixelflow_core::Field {
                                use ::pixelflow_core::{X, Y, Z, W, ManifoldExt, ManifoldCompat, Manifold, Let, Var, WithContext, CtxVar, GradientMag2D, GradientMag3D, Antialias2D, Antialias3D, Curvature2D, Normalized2D, Normalized3D, V, DX, DY, DZ, DXX, DXY, DYY};
                                #peano_imports

                                // Evaluate manifold parameters at current point (borrows via &self)
                                #manifold_eval_stmts

                                // Build the ZST expression tree using Var<N> for ALL parameters
                                let __expr = { #body };

                                // Wrap in nested Let bindings and evaluate
                                #at_binding
                            }
                        }

                        |#(#closure_params),*| __Kernel { #(#field_names),* }
                    }
                }
            }
        } else {
            // Has manifold parameters (possibly mixed with scalar) - need generics and trait bounds

            // Check if we have an explicit return type - if not, use generic domain
            let has_return_type = self.analyzed.def.return_ty.is_some();

            if has_return_type {
                // Explicit return type → fixed domain
                let trait_bounds: Vec<TokenStream> = generic_names
                    .iter()
                    .map(|g| {
                        quote! { #g: ::pixelflow_core::Manifold<__Domain, Output = __Scalar> }
                    })
                    .collect();

                quote! {
                    {
                        type __Domain = #domain_type;
                        type __Scalar = #scalar_type;

                        struct __Kernel<#(#generic_names),*> { #(#struct_fields),* }

                        // Clone when all fields are Clone
                        impl<#(#generic_names: Clone),*> Clone for __Kernel<#(#generic_names),*> {
                            fn clone(&self) -> Self {
                                Self { #(#field_names: self.#field_names.clone()),* }
                            }
                        }

                        impl<#(#generic_names),*> ::pixelflow_core::Manifold<__Domain> for __Kernel<#(#generic_names),*>
                        where
                            #(#trait_bounds),*
                        {
                            type Output = #output_type;

                            #[inline(always)]
                            fn eval(
                                &self,
                                __p: __Domain,
                            ) -> #output_type {
                                use ::pixelflow_core::{X, Y, Z, W, ManifoldExt, ManifoldCompat, Manifold, Let, Var, WithContext, CtxVar, GradientMag2D, GradientMag3D, Antialias2D, Antialias3D, Curvature2D, Normalized2D, Normalized3D, V, DX, DY, DZ, DXX, DXY, DYY};
                                #peano_imports

                                // Evaluate manifold parameters at current point (borrows via &self)
                                #manifold_eval_stmts

                                // Build the ZST expression tree using Var<N> for ALL parameters
                                let __expr = { #body };

                                // Wrap in nested Let bindings and evaluate
                                #at_binding
                            }
                        }

                        |#(#closure_params),*| __Kernel { #(#field_names),* }
                    }
                }
            } else {
                // No return type → generic domain P
                // NOTE: Mixed manifold + scalar params with generic domain is complex
                // For now, this requires an explicit return type annotation

                quote! {
                    {
                        struct __Kernel<#(#generic_names),*> { #(#struct_fields),* }

                        // Clone when all fields are Clone
                        impl<#(#generic_names: Clone),*> Clone for __Kernel<#(#generic_names),*> {
                            fn clone(&self) -> Self {
                                Self { #(#field_names: self.#field_names.clone()),* }
                            }
                        }

                        // Generic over domain P
                        // Manifold params must output Field for mixed param type unification
                        impl<#(#generic_names),*, __P> ::pixelflow_core::Manifold<__P> for __Kernel<#(#generic_names),*>
                        where
                            __P: Copy + Send + Sync + ::pixelflow_core::Spatial,
                            #(#generic_names: ::pixelflow_core::Manifold<__P, Output = ::pixelflow_core::Field>),*,
                        {
                            type Output = ::pixelflow_core::Field;

                            #[inline(always)]
                            fn eval(
                                &self,
                                __p: __P,
                            ) -> ::pixelflow_core::Field {
                                use ::pixelflow_core::{X, Y, Z, W, ManifoldExt, ManifoldCompat, Manifold, Let, Var, WithContext, CtxVar, GradientMag2D, GradientMag3D, Antialias2D, Antialias3D, Curvature2D, Normalized2D, Normalized3D, V, DX, DY, DZ, DXX, DXY, DYY};
                                #peano_imports

                                // Evaluate manifold parameters at current point (borrows via &self)
                                #manifold_eval_stmts

                                // Build the ZST expression tree using Var<N> for ALL parameters
                                let __expr = { #body };

                                // Wrap in nested Let bindings and evaluate
                                #at_binding
                            }
                        }

                        |#(#closure_params),*| __Kernel { #(#field_names),* }
                    }
                }
            }
        }
    }

    /// Emit the Peano type imports needed based on parameter + literal count.
    fn emit_peano_imports(&self) -> TokenStream {
        // In Jet mode: need types for params + literals
        // In non-Jet mode: only need types for params (literals are inlined)
        let total = if self.use_jet_wrapper {
            self.analyzed.def.params.len() + self.collected_literals.len()
        } else {
            self.analyzed.def.params.len()
        };

        if total == 0 {
            return quote! {};
        }

        // Import N0..N{total-1}
        let imports: Vec<TokenStream> = (0..total)
            .map(|i| {
                let name_str = format!("N{}", i);
                let name = syn::Ident::new(&name_str, proc_macro2::Span::call_site());
                quote! { #name }
            })
            .collect();

        quote! { use ::pixelflow_core::binding::{ #(#imports),* }; }
    }

    /// Emit unified WithContext/CtxVar binding for params (and Let for literals).
    ///
    /// Returns two things:
    /// 1. Statements for pre-evaluating manifold params (when mixed with scalars)
    /// 2. WithContext::new(tuple, body) for params, wrapped in Let for literals
    ///
    /// NEW APPROACH: Uses flat WithContext tuple instead of nested Let for parameters.
    /// This avoids trait solver explosion for >4 parameters.
    ///
    /// Binding order:
    /// - Parameters → WithContext flat tuple (CtxVar<N0>, CtxVar<N1>, ...)
    /// - Literals (Jet mode only) → nested Let (wraps the WithContext)
    ///
    /// ## Mixed Param Handling
    ///
    /// When manifold params are mixed with scalar params, we must eagerly evaluate
    /// the manifold params to get concrete `__Scalar` values for type unification.
    fn emit_unified_binding(&self) -> (TokenStream, TokenStream) {
        let params = &self.analyzed.def.params;

        if params.is_empty() && self.collected_literals.is_empty() {
            // No bindings needed - evaluate expression directly
            return (quote! {}, quote! { __expr.eval(__p) });
        }

        // Determine if we need to pre-evaluate manifold params
        let manifold_count = self.manifold_indices.len();
        let has_scalar_params = params.iter().any(|p| matches!(p.kind, ParamKind::Scalar(_)));
        let needs_pre_eval = manifold_count > 0 && (manifold_count > 1 || has_scalar_params);

        // Determine the scalar type to use for pre-evaluation
        let has_return_type = self.analyzed.def.return_ty.is_some();
        let scalar_type_token = if has_return_type {
            quote! { __Scalar }
        } else {
            quote! { ::pixelflow_core::Field }
        };

        // Pre-evaluate manifolds to get concrete scalar values
        let mut pre_eval_stmts = Vec::new();
        if needs_pre_eval {
            for param in params.iter() {
                if matches!(param.kind, ParamKind::Manifold) {
                    let name = &param.name;
                    let eval_name = syn::Ident::new(
                        &format!("__eval_{}", name),
                        proc_macro2::Span::call_site(),
                    );
                    pre_eval_stmts.push(quote! {
                        let #eval_name: #scalar_type_token = self.#name.eval(__p);
                    });
                }
            }
        }

        // Build the parameter binding using WithContext for flat tuple approach
        let result = if params.is_empty() {
            // No params, just the expression
            quote! { __expr }
        } else {
            // Build tuple of param values ordered by index
            // Index 0 goes to tuple position 0, index 1 to position 1, etc.
            let n = params.len();
            let mut indexed_params: Vec<(usize, TokenStream)> = Vec::new();

            for param in params.iter() {
                let name = &param.name;
                let idx = self.param_indices[&name.to_string()];

                let param_value = match &param.kind {
                    ParamKind::Manifold => {
                        if needs_pre_eval {
                            // Use pre-evaluated value for type unification
                            let eval_name = syn::Ident::new(
                                &format!("__eval_{}", name),
                                proc_macro2::Span::call_site(),
                            );
                            quote! { #eval_name }
                        } else {
                            // Single manifold param without scalars - pass reference
                            quote! { &self.#name }
                        }
                    }
                    ParamKind::Scalar(_) => {
                        // For Jet domains, wrap f32 params as constant jets
                        if self.use_jet_wrapper {
                            quote! { __Scalar::constant(::pixelflow_core::Field::from(self.#name)) }
                        } else if needs_pre_eval {
                            // Mixed with manifolds: wrap scalar as Field
                            quote! { #scalar_type_token::from(self.#name) }
                        } else {
                            quote! { self.#name }
                        }
                    }
                };

                indexed_params.push((idx, param_value));
            }

            // Sort by index to get correct tuple order
            indexed_params.sort_by_key(|(idx, _)| *idx);
            let param_values: Vec<_> = indexed_params.into_iter().map(|(_, val)| val).collect();

            // Generate the WithContext tuple
            // CRITICAL: For 1-element tuples, we need a trailing comma: (value,)
            // Without it, Rust interprets (value) as just parentheses, not a tuple!
            if param_values.len() == 1 {
                let val = &param_values[0];
                quote! {
                    WithContext::new((#val,), __expr)
                }
            } else {
                quote! {
                    WithContext::new((#(#param_values),*), __expr)
                }
            }
        };

        // Wrap in Let bindings for literals (Jet mode only)
        let result = if self.use_jet_wrapper && !self.collected_literals.is_empty() {
            let mut wrapped = result;
            // Wrap literals (innermost - reversed so last literal is innermost)
            for collected in self.collected_literals.iter().rev() {
                let lit = &collected.lit;
                let lit_value = quote! { __Scalar::constant(::pixelflow_core::Field::from(#lit)) };
                wrapped = quote! {
                    Let::new(#lit_value, #wrapped)
                };
            }
            wrapped
        } else {
            result
        };

        // Evaluate the expression
        let at_binding = quote! { #result.eval(__p) };

        // Return pre-eval statements and the binding
        let stmts = if pre_eval_stmts.is_empty() {
            quote! {}
        } else {
            quote! { #(#pre_eval_stmts)* }
        };
        (stmts, at_binding)
    }

    /// Emit code for an annotated expression (pure, no mutation).
    ///
    /// Literals with var_index become Var<N> references.
    /// This is the clean functional version that works with the annotation pass.
    fn emit_annotated_expr(&self, expr: &AnnotatedExpr) -> TokenStream {
        match expr {
            AnnotatedExpr::Ident(ident_expr) => {
                let name = &ident_expr.name;
                let name_str = name.to_string();

                match self.analyzed.symbols.lookup(&name_str) {
                    Some(symbol) => match symbol.kind {
                        SymbolKind::Intrinsic => {
                            // Intrinsics (X, Y, Z, W) emitted as-is
                            quote! { #name }
                        }
                        SymbolKind::Parameter | SymbolKind::ManifoldParam => {
                            // Both scalar and manifold parameters become CtxVar::<N{index}>::new()
                            // (switched from Var to CtxVar for flat WithContext tuple approach)
                            if let Some(&idx) = self.param_indices.get(&name_str) {
                                if idx < 256 {
                                    let peano_name_str = format!("N{}", idx);
                                    let peano_name = syn::Ident::new(
                                        &peano_name_str,
                                        proc_macro2::Span::call_site(),
                                    );
                                    quote! { CtxVar::<#peano_name>::new() }
                                } else {
                                    let err_msg = format!(
                                        "kernel! supports max 256 bindings, found index {}",
                                        idx
                                    );
                                    quote! { compile_error!(#err_msg) }
                                }
                            } else {
                                quote! { #name }
                            }
                        }
                        SymbolKind::Local => {
                            // Locals emitted as-is
                            quote! { #name }
                        }
                    },
                    None => {
                        // Unknown - emit as-is
                        quote! { #name }
                    }
                }
            }

            AnnotatedExpr::Literal(lit) => {
                if self.use_jet_wrapper {
                    // Jet mode: literals are bound via Let, emit as Var reference
                    if let Some(collection_idx) = lit.var_index {
                        // The collection_idx is the order in which literals were encountered.
                        // We need to invert this because the Let binding order puts:
                        // - Last literal (innermost Let) at N0
                        // - First literal at N(literal_count - 1)
                        let literal_count = self.collected_literals.len();
                        let var_idx = (literal_count - 1) - collection_idx;

                        if var_idx < 256 {
                            let peano_name_str = format!("N{}", var_idx);
                            let peano_name = syn::Ident::new(
                                &peano_name_str,
                                proc_macro2::Span::call_site(),
                            );
                            quote! { Var::<#peano_name>::new() }
                        } else {
                            let err_msg = format!(
                                "kernel! supports max 256 bindings, found index {}",
                                var_idx
                            );
                            quote! { compile_error!(#err_msg) }
                        }
                    } else {
                        // Shouldn't happen in Jet mode, but fallback to direct emission
                        let l = &lit.lit;
                        quote! { __Scalar::constant(::pixelflow_core::Field::from(#l)) }
                    }
                } else {
                    // Non-Jet mode: emit literal directly (no Let binding needed)
                    let l = &lit.lit;
                    quote! { #l }
                }
            }

            AnnotatedExpr::Binary(binary) => {
                let lhs = self.emit_annotated_expr(&binary.lhs);
                let rhs = self.emit_annotated_expr(&binary.rhs);

                match binary.op {
                    BinaryOp::Add => quote! { #lhs + #rhs },
                    BinaryOp::Sub => quote! { #lhs - #rhs },
                    BinaryOp::Mul => quote! { #lhs * #rhs },
                    BinaryOp::Div => quote! { #lhs / #rhs },
                    BinaryOp::Rem => quote! { #lhs % #rhs },
                    BinaryOp::Lt => quote! { #lhs.lt(#rhs) },
                    BinaryOp::Le => quote! { #lhs.le(#rhs) },
                    BinaryOp::Gt => quote! { #lhs.gt(#rhs) },
                    BinaryOp::Ge => quote! { #lhs.ge(#rhs) },
                    BinaryOp::Eq => quote! { #lhs.eq(#rhs) },
                    BinaryOp::Ne => quote! { #lhs.ne(#rhs) },
                    BinaryOp::BitAnd => quote! { #lhs & #rhs },
                    BinaryOp::BitOr => quote! { #lhs | #rhs },
                }
            }

            AnnotatedExpr::Unary(unary) => {
                let operand = self.emit_annotated_expr(&unary.operand);
                match unary.op {
                    UnaryOp::Neg => quote! { #operand.neg() },
                    UnaryOp::Not => quote! { !#operand },
                }
            }

            AnnotatedExpr::MethodCall(call) => {
                let receiver = self.emit_annotated_expr(&call.receiver);
                let method = &call.method;
                let args: Vec<TokenStream> = call.args.iter()
                    .map(|a| self.emit_annotated_expr(a))
                    .collect();

                if args.is_empty() {
                    quote! { #receiver.#method() }
                } else {
                    quote! { #receiver.#method(#(#args),*) }
                }
            }

            AnnotatedExpr::Call(call) => {
                // Free function call: V(m), DX(expr), etc.
                // Emit with transformed arguments (manifold params become Var<N>)
                let func = &call.func;
                let args: Vec<TokenStream> = call.args.iter()
                    .map(|a| self.emit_annotated_expr(a))
                    .collect();

                if args.is_empty() {
                    quote! { #func() }
                } else {
                    quote! { #func(#(#args),*) }
                }
            }

            AnnotatedExpr::Block(block) => {
                let stmts: Vec<TokenStream> = block.stmts.iter()
                    .map(|s| self.emit_annotated_stmt(s))
                    .collect();

                let final_expr = block.expr.as_ref().map(|e| self.emit_annotated_expr(e));

                match final_expr {
                    Some(expr) => quote! {
                        {
                            #(#stmts)*
                            #expr
                        }
                    },
                    None => quote! {
                        {
                            #(#stmts)*
                        }
                    },
                }
            }

            AnnotatedExpr::Paren(inner) => {
                let inner_code = self.emit_annotated_expr(inner);
                quote! { (#inner_code) }
            }

            AnnotatedExpr::Verbatim(syn_expr) => {
                syn_expr.to_token_stream()
            }
        }
    }

    fn emit_annotated_stmt(&self, stmt: &AnnotatedStmt) -> TokenStream {
        match stmt {
            AnnotatedStmt::Let(let_stmt) => {
                let name = &let_stmt.name;
                let init = self.emit_annotated_expr(&let_stmt.init);

                match &let_stmt.ty {
                    Some(ty) => quote! { let #name: #ty = #init; },
                    None => quote! { let #name = #init; },
                }
            }
            AnnotatedStmt::Expr(expr) => {
                let code = self.emit_annotated_expr(expr);
                quote! { #code; }
            }
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::parser::parse;
    use crate::sema::analyze;
    use quote::quote;

    fn compile(input: TokenStream) -> TokenStream {
        let kernel = parse(input).unwrap();
        let analyzed = analyze(kernel).unwrap();
        emit(analyzed)
    }

    #[test]
    fn emit_simple_kernel() {
        let input = quote! { |cx: f32| X - cx };
        let output = compile(input);
        let output_str = output.to_string();

        // Should contain struct definition
        assert!(output_str.contains("struct __Kernel"));
        // Should use Var::<N0> for the single parameter
        assert!(
            output_str.contains("Var :: < N0 >"),
            "Expected Var::<N0>, got: {}",
            output_str
        );
        // Should have Let binding
        assert!(
            output_str.contains("Let :: new"),
            "Expected Let::new, got: {}",
            output_str
        );
    }

    #[test]
    fn emit_two_params() {
        let input = quote! { |cx: f32, cy: f32| (X - cx) + (Y - cy) };
        let output = compile(input);
        let output_str = output.to_string();

        // cx → Var::<N1> (first param, highest index)
        // cy → Var::<N0> (second param, head of stack)
        assert!(
            output_str.contains("Var :: < N1 >"),
            "Expected Var::<N1> for cx, got: {}",
            output_str
        );
        assert!(
            output_str.contains("Var :: < N0 >"),
            "Expected Var::<N0> for cy, got: {}",
            output_str
        );
        // Should have nested Let bindings
        assert!(
            output_str.contains("Let :: new (self . cx , Let :: new (self . cy"),
            "Expected nested Let bindings, got: {}",
            output_str
        );
    }

    #[test]
    fn emit_three_params() {
        let input = quote! { |a: f32, b: f32, c: f32| a + b + c };
        let output = compile(input);
        let output_str = output.to_string();

        // a → Var::<N2>, b → Var::<N1>, c → Var::<N0>
        assert!(
            output_str.contains("Var :: < N2 >"),
            "Expected Var::<N2> for a"
        );
        assert!(
            output_str.contains("Var :: < N1 >"),
            "Expected Var::<N1> for b"
        );
        assert!(
            output_str.contains("Var :: < N0 >"),
            "Expected Var::<N0> for c"
        );
        // Should import N0, N1, N2
        assert!(output_str.contains("N0"));
        assert!(output_str.contains("N1"));
        assert!(output_str.contains("N2"));
    }

    #[test]
    fn emit_empty_params() {
        let input = quote! { || X + Y };
        let output = compile(input);
        let output_str = output.to_string();

        // Should have unit struct
        assert!(output_str.contains("struct __Kernel ;"));
        // Should evaluate directly on __p
        assert!(
            output_str.contains("__expr . eval (__p)"),
            "Expected direct eval on __p, got: {}",
            output_str
        );
    }

    #[test]
    fn emit_method_calls() {
        let input = quote! { |r: f32| (X * X + Y * Y).sqrt() - r };
        let output = compile(input);
        let output_str = output.to_string();

        // r → Var::<N0>
        assert!(output_str.contains(". sqrt ()"));
        assert!(
            output_str.contains("Var :: < N0 >"),
            "Expected Var::<N0> for r"
        );
    }

    #[test]
    fn emit_manifold_param() {
        let input = quote! { |inner: kernel, r: f32| inner - r };
        let output = compile(input);
        let output_str = output.to_string();

        // Should have generic struct: struct __Kernel<M0> { inner: M0, r: f32 }
        assert!(
            output_str.contains("struct __Kernel < M0 >"),
            "Expected generic struct, got: {}",
            output_str
        );

        // Should have trait bound for M0
        assert!(
            output_str.contains("M0 : :: pixelflow_core :: Manifold < __Domain"),
            "Expected trait bound for M0, got: {}",
            output_str
        );

        // inner → Var::<N1>, r → Var::<N0>
        assert!(
            output_str.contains("Var :: < N1 >"),
            "Expected Var::<N1> for inner"
        );
        assert!(
            output_str.contains("Var :: < N0 >"),
            "Expected Var::<N0> for r"
        );

        // Should evaluate manifold: let __m0 = self.inner.eval(__p);
        assert!(
            output_str.contains("let __m0 = self . inner . eval (__p)"),
            "Expected manifold eval, got: {}",
            output_str
        );
    }

    #[test]
    fn emit_multiple_manifold_params() {
        let input = quote! { |a: kernel, b: kernel| a + b };
        let output = compile(input);
        let output_str = output.to_string();

        // Should have two generic params
        assert!(
            output_str.contains("struct __Kernel < M0 , M1 >"),
            "Expected two generics, got: {}",
            output_str
        );

        // Both params become Var references
        assert!(
            output_str.contains("Var :: < N1 >"),
            "Expected Var::<N1> for a"
        );
        assert!(
            output_str.contains("Var :: < N0 >"),
            "Expected Var::<N0> for b"
        );

        // Should have two manifold evals
        assert!(
            output_str.contains("let __m0 = self . a . eval (__p)"),
            "Expected __m0 eval"
        );
        assert!(
            output_str.contains("let __m1 = self . b . eval (__p)"),
            "Expected __m1 eval"
        );
    }
}
